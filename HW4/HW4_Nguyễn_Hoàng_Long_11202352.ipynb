{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vvPI9jom5lH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import vgg13\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((28,28)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Download and load the training data\n",
        "trainset = torchvision.datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
        "testset = torchvision.datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "D5rbbjtiqH6X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f221a567-9a9e-428b-d576-d0e0e4b6b3a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 16185612.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 300116.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 4933676.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 16686458.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MiniVGG(nn.Module):\n",
        "    def __init__(self, num_classes= 10):\n",
        "        super(MiniVGG, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(in_channels= 1, out_channels= 64, kernel_size= (3,3), stride= (1,1), padding= 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels= 64, out_channels= 64, kernel_size= (3,3), stride=(1,1), padding= 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size= (2,2), stride= (2,2)),\n",
        "\n",
        "            nn.Conv2d(in_channels= 64, out_channels= 128, kernel_size= (3,3), stride= (1,1), padding= 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels= 128, out_channels= 128, kernel_size= (3,3), stride=(1,1), padding= 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size= (2,2), stride= (2,2)),\n",
        "\n",
        "            nn.Conv2d(in_channels= 128, out_channels= 256, kernel_size= (3,3), stride= (1,1), padding= 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels= 256, out_channels= 256, kernel_size= (3,3), stride=(1,1), padding= 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size= (2,2), stride= (2,2)))\n",
        "\n",
        "        self.classifier = nn.Linear(256 * 3 * 3, 10)\n",
        "        nn.init.normal_(self.classifier.weight, 0, 0.01)\n",
        "        nn.init.constant_(self.classifier.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "9_Ajzm0DH42h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import vgg13\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# Specify the path to the pre-trained model on Google Drive\n",
        "model_weights_path = '/content/drive/MyDrive/Colab Notebooks/DeepLearning/cifar10_mini_vgg.pth'\n",
        "\n",
        "# Load the VGG13 model\n",
        "model_cifar = MiniVGG() #vgg13(pretrained=False)\n",
        "# model_cifar.features[0] = torch.nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n",
        "# Load pre-trained weights\n",
        "model_cifar.load_state_dict(torch.load(model_weights_path), strict=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mi_4dbrT0-ms",
        "outputId": "e523c62c-0c51-48c9-edb9-d95c85f0b38c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# num_classes = 10  # FashionMNIST has 10 classes\n",
        "# model_cifar.classifier[-1] = nn.Linear(4096, num_classes)\n",
        "# Freeze the Pre-Trained Model Layers and unfreeze the last layer\n",
        "for param in model_cifar.parameters():\n",
        "    param.requires_grad = False\n",
        "for param in model_cifar.classifier.parameters():\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "id": "d9lU0xD4t8vR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cifar.to(device)\n",
        "# Example optimizer and criterion\n",
        "optimizer = torch.optim.SGD(model_cifar.parameters(), lr=0.001, momentum=0.9)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "# Assuming you have your train_loader and test_loader ready\n",
        "n_total_batches = len(trainloader)\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model_cifar.train()\n",
        "    for i, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_cifar(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{n_total_batches}], Loss: {loss.item():.4f}')\n",
        "    # Validation\n",
        "    model_cifar.eval()\n",
        "    with torch.no_grad():\n",
        "        total_correct = 0\n",
        "        total_samples = 0\n",
        "        for inputs, labels in testloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model_cifar(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "        accuracy = total_correct / total_samples\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}')\n",
        "        print('-' * 40)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heg3meDD5LLU",
        "outputId": "7e1391e4-02ab-4122-db54-1e1bc50bd8c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Batch [100/938], Loss: 1.8142\n",
            "Epoch [1/5], Batch [200/938], Loss: 1.1092\n",
            "Epoch [1/5], Batch [300/938], Loss: 0.8716\n",
            "Epoch [1/5], Batch [400/938], Loss: 0.4554\n",
            "Epoch [1/5], Batch [500/938], Loss: 0.6518\n",
            "Epoch [1/5], Batch [600/938], Loss: 0.7709\n",
            "Epoch [1/5], Batch [700/938], Loss: 0.8202\n",
            "Epoch [1/5], Batch [800/938], Loss: 0.5456\n",
            "Epoch [1/5], Batch [900/938], Loss: 0.6313\n",
            "Epoch [1/5], Loss: 0.8541, Accuracy: 0.8307\n",
            "----------------------------------------\n",
            "Epoch [2/5], Batch [100/938], Loss: 0.6013\n",
            "Epoch [2/5], Batch [200/938], Loss: 0.2657\n",
            "Epoch [2/5], Batch [300/938], Loss: 0.3865\n",
            "Epoch [2/5], Batch [400/938], Loss: 0.4239\n",
            "Epoch [2/5], Batch [500/938], Loss: 0.4479\n",
            "Epoch [2/5], Batch [600/938], Loss: 0.6449\n",
            "Epoch [2/5], Batch [700/938], Loss: 0.4650\n",
            "Epoch [2/5], Batch [800/938], Loss: 0.4998\n",
            "Epoch [2/5], Batch [900/938], Loss: 0.2791\n",
            "Epoch [2/5], Loss: 0.3730, Accuracy: 0.8495\n",
            "----------------------------------------\n",
            "Epoch [3/5], Batch [100/938], Loss: 0.5291\n",
            "Epoch [3/5], Batch [200/938], Loss: 0.4746\n",
            "Epoch [3/5], Batch [300/938], Loss: 0.3329\n",
            "Epoch [3/5], Batch [400/938], Loss: 0.5714\n",
            "Epoch [3/5], Batch [500/938], Loss: 0.5560\n",
            "Epoch [3/5], Batch [600/938], Loss: 0.4825\n",
            "Epoch [3/5], Batch [700/938], Loss: 0.4664\n",
            "Epoch [3/5], Batch [800/938], Loss: 0.5420\n",
            "Epoch [3/5], Batch [900/938], Loss: 0.2885\n",
            "Epoch [3/5], Loss: 0.8773, Accuracy: 0.8522\n",
            "----------------------------------------\n",
            "Epoch [4/5], Batch [100/938], Loss: 0.4146\n",
            "Epoch [4/5], Batch [200/938], Loss: 0.4312\n",
            "Epoch [4/5], Batch [300/938], Loss: 0.3026\n",
            "Epoch [4/5], Batch [400/938], Loss: 0.1523\n",
            "Epoch [4/5], Batch [500/938], Loss: 0.5753\n",
            "Epoch [4/5], Batch [600/938], Loss: 0.4206\n",
            "Epoch [4/5], Batch [700/938], Loss: 0.3202\n",
            "Epoch [4/5], Batch [800/938], Loss: 0.3155\n",
            "Epoch [4/5], Batch [900/938], Loss: 0.5317\n",
            "Epoch [4/5], Loss: 0.1393, Accuracy: 0.8723\n",
            "----------------------------------------\n",
            "Epoch [5/5], Batch [100/938], Loss: 0.2252\n",
            "Epoch [5/5], Batch [200/938], Loss: 0.2719\n",
            "Epoch [5/5], Batch [300/938], Loss: 0.3406\n",
            "Epoch [5/5], Batch [400/938], Loss: 0.4203\n",
            "Epoch [5/5], Batch [500/938], Loss: 0.3820\n",
            "Epoch [5/5], Batch [600/938], Loss: 0.2851\n",
            "Epoch [5/5], Batch [700/938], Loss: 0.4739\n",
            "Epoch [5/5], Batch [800/938], Loss: 0.3256\n",
            "Epoch [5/5], Batch [900/938], Loss: 0.4385\n",
            "Epoch [5/5], Loss: 0.1174, Accuracy: 0.8674\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_weights_path = '/content/drive/MyDrive/Colab Notebooks/DeepLearning/mnist_mini_vgg.pth'\n",
        "\n",
        "# Load the VGG13 model\n",
        "model_mnist = MiniVGG() # vgg13(pretrained=False)\n",
        "# model_mnist.features[0] = torch.nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n",
        "# Load pre-trained weights\n",
        "model_mnist.load_state_dict(torch.load(model_weights_path), strict=False)\n",
        "\n",
        "# num_classes = 10  # FashionMNIST has 10 classes\n",
        "# model_mnist.classifier[-1] = nn.Linear(4096, num_classes)\n",
        "# Freeze the Pre-Trained Model Layers and unfreeze the last layer\n",
        "for param in model_mnist.parameters():\n",
        "    param.requires_grad = False\n",
        "for param in model_mnist.classifier.parameters():\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "id": "-o_2J6oMJL_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_mnist.to(device)\n",
        "# Example optimizer and criterion\n",
        "optimizer = torch.optim.SGD(model_mnist.parameters(), lr=0.001, momentum=0.9)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "# Assuming you have your train_loader and test_loader ready\n",
        "n_total_batches = len(trainloader)\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model_mnist.train()\n",
        "    for i, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_mnist(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{n_total_batches}], Loss: {loss.item():.4f}')\n",
        "    # Validation\n",
        "    model_mnist.eval()\n",
        "    with torch.no_grad():\n",
        "        total_correct = 0\n",
        "        total_samples = 0\n",
        "        for inputs, labels in testloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model_mnist(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "        accuracy = total_correct / total_samples\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}')\n",
        "        print('-' * 40)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJjv9pECKVJD",
        "outputId": "5f2e87c9-d7eb-46e7-98c4-bb66b859edf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Batch [100/938], Loss: 1.3604\n",
            "Epoch [1/5], Batch [200/938], Loss: 0.6518\n",
            "Epoch [1/5], Batch [300/938], Loss: 0.7750\n",
            "Epoch [1/5], Batch [400/938], Loss: 0.6119\n",
            "Epoch [1/5], Batch [500/938], Loss: 0.5567\n",
            "Epoch [1/5], Batch [600/938], Loss: 1.0333\n",
            "Epoch [1/5], Batch [700/938], Loss: 0.6334\n",
            "Epoch [1/5], Batch [800/938], Loss: 0.7004\n",
            "Epoch [1/5], Batch [900/938], Loss: 0.5256\n",
            "Epoch [1/5], Loss: 0.9660, Accuracy: 0.7869\n",
            "----------------------------------------\n",
            "Epoch [2/5], Batch [100/938], Loss: 0.8204\n",
            "Epoch [2/5], Batch [200/938], Loss: 0.6716\n",
            "Epoch [2/5], Batch [300/938], Loss: 0.5600\n",
            "Epoch [2/5], Batch [400/938], Loss: 0.6921\n",
            "Epoch [2/5], Batch [500/938], Loss: 0.5475\n",
            "Epoch [2/5], Batch [600/938], Loss: 0.5556\n",
            "Epoch [2/5], Batch [700/938], Loss: 0.5907\n",
            "Epoch [2/5], Batch [800/938], Loss: 0.6066\n",
            "Epoch [2/5], Batch [900/938], Loss: 0.5051\n",
            "Epoch [2/5], Loss: 0.5854, Accuracy: 0.8120\n",
            "----------------------------------------\n",
            "Epoch [3/5], Batch [100/938], Loss: 0.5291\n",
            "Epoch [3/5], Batch [200/938], Loss: 0.4664\n",
            "Epoch [3/5], Batch [300/938], Loss: 0.5887\n",
            "Epoch [3/5], Batch [400/938], Loss: 0.3413\n",
            "Epoch [3/5], Batch [500/938], Loss: 0.3428\n",
            "Epoch [3/5], Batch [600/938], Loss: 0.4684\n",
            "Epoch [3/5], Batch [700/938], Loss: 0.4548\n",
            "Epoch [3/5], Batch [800/938], Loss: 0.5700\n",
            "Epoch [3/5], Batch [900/938], Loss: 0.4743\n",
            "Epoch [3/5], Loss: 0.5972, Accuracy: 0.8182\n",
            "----------------------------------------\n",
            "Epoch [4/5], Batch [100/938], Loss: 0.3708\n",
            "Epoch [4/5], Batch [200/938], Loss: 0.5696\n",
            "Epoch [4/5], Batch [300/938], Loss: 0.6363\n",
            "Epoch [4/5], Batch [400/938], Loss: 0.5026\n",
            "Epoch [4/5], Batch [500/938], Loss: 0.4562\n",
            "Epoch [4/5], Batch [600/938], Loss: 0.6662\n",
            "Epoch [4/5], Batch [700/938], Loss: 0.5973\n",
            "Epoch [4/5], Batch [800/938], Loss: 0.5314\n",
            "Epoch [4/5], Batch [900/938], Loss: 0.5663\n",
            "Epoch [4/5], Loss: 0.3005, Accuracy: 0.8230\n",
            "----------------------------------------\n",
            "Epoch [5/5], Batch [100/938], Loss: 0.4853\n",
            "Epoch [5/5], Batch [200/938], Loss: 0.5398\n",
            "Epoch [5/5], Batch [300/938], Loss: 0.4317\n",
            "Epoch [5/5], Batch [400/938], Loss: 0.5672\n",
            "Epoch [5/5], Batch [500/938], Loss: 0.5761\n",
            "Epoch [5/5], Batch [600/938], Loss: 0.5106\n",
            "Epoch [5/5], Batch [700/938], Loss: 0.5648\n",
            "Epoch [5/5], Batch [800/938], Loss: 0.4442\n",
            "Epoch [5/5], Batch [900/938], Loss: 0.5415\n",
            "Epoch [5/5], Loss: 0.8224, Accuracy: 0.8227\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_HW3 = MiniVGG()\n",
        "\n",
        "model_HW3.to(device)\n",
        "# Example optimizer and criterion\n",
        "optimizer = torch.optim.SGD(model_HW3.parameters(), lr=0.001, momentum=0.9)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "# Assuming you have your train_loader and test_loader ready\n",
        "n_total_batches = len(trainloader)\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model_HW3.train()\n",
        "    for i, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_HW3(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{n_total_batches}], Loss: {loss.item():.4f}')\n",
        "    # Validation\n",
        "    model_HW3.eval()\n",
        "    with torch.no_grad():\n",
        "        total_correct = 0\n",
        "        total_samples = 0\n",
        "        for inputs, labels in testloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model_HW3(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "        accuracy = total_correct / total_samples\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}')\n",
        "        print('-' * 40)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nxn8A5I0L2xx",
        "outputId": "343dd242-f991-428d-c630-d2147a7aa3c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Batch [100/938], Loss: 2.3021\n",
            "Epoch [1/5], Batch [200/938], Loss: 2.3012\n",
            "Epoch [1/5], Batch [300/938], Loss: 2.3002\n",
            "Epoch [1/5], Batch [400/938], Loss: 2.2969\n",
            "Epoch [1/5], Batch [500/938], Loss: 2.2951\n",
            "Epoch [1/5], Batch [600/938], Loss: 2.2888\n",
            "Epoch [1/5], Batch [700/938], Loss: 2.2649\n",
            "Epoch [1/5], Batch [800/938], Loss: 2.0005\n",
            "Epoch [1/5], Batch [900/938], Loss: 1.2626\n",
            "Epoch [1/5], Loss: 1.1689, Accuracy: 0.4848\n",
            "----------------------------------------\n",
            "Epoch [2/5], Batch [100/938], Loss: 0.8911\n",
            "Epoch [2/5], Batch [200/938], Loss: 0.9897\n",
            "Epoch [2/5], Batch [300/938], Loss: 0.7467\n",
            "Epoch [2/5], Batch [400/938], Loss: 0.9631\n",
            "Epoch [2/5], Batch [500/938], Loss: 0.7620\n",
            "Epoch [2/5], Batch [600/938], Loss: 0.8269\n",
            "Epoch [2/5], Batch [700/938], Loss: 0.6882\n",
            "Epoch [2/5], Batch [800/938], Loss: 0.6701\n",
            "Epoch [2/5], Batch [900/938], Loss: 0.6189\n",
            "Epoch [2/5], Loss: 0.6655, Accuracy: 0.7484\n",
            "----------------------------------------\n",
            "Epoch [3/5], Batch [100/938], Loss: 0.7168\n",
            "Epoch [3/5], Batch [200/938], Loss: 0.7507\n",
            "Epoch [3/5], Batch [300/938], Loss: 0.6682\n",
            "Epoch [3/5], Batch [400/938], Loss: 0.3812\n",
            "Epoch [3/5], Batch [500/938], Loss: 0.6516\n",
            "Epoch [3/5], Batch [600/938], Loss: 0.6817\n",
            "Epoch [3/5], Batch [700/938], Loss: 0.4452\n",
            "Epoch [3/5], Batch [800/938], Loss: 0.5708\n",
            "Epoch [3/5], Batch [900/938], Loss: 0.4221\n",
            "Epoch [3/5], Loss: 0.4231, Accuracy: 0.7784\n",
            "----------------------------------------\n",
            "Epoch [4/5], Batch [100/938], Loss: 0.4435\n",
            "Epoch [4/5], Batch [200/938], Loss: 0.4099\n",
            "Epoch [4/5], Batch [300/938], Loss: 0.3957\n",
            "Epoch [4/5], Batch [400/938], Loss: 0.7021\n",
            "Epoch [4/5], Batch [500/938], Loss: 0.4920\n",
            "Epoch [4/5], Batch [600/938], Loss: 0.4247\n",
            "Epoch [4/5], Batch [700/938], Loss: 0.6463\n",
            "Epoch [4/5], Batch [800/938], Loss: 0.4156\n",
            "Epoch [4/5], Batch [900/938], Loss: 0.3575\n",
            "Epoch [4/5], Loss: 0.1981, Accuracy: 0.8281\n",
            "----------------------------------------\n",
            "Epoch [5/5], Batch [100/938], Loss: 0.4570\n",
            "Epoch [5/5], Batch [200/938], Loss: 0.3336\n",
            "Epoch [5/5], Batch [300/938], Loss: 0.3990\n",
            "Epoch [5/5], Batch [400/938], Loss: 0.3431\n",
            "Epoch [5/5], Batch [500/938], Loss: 0.4132\n",
            "Epoch [5/5], Batch [600/938], Loss: 0.3897\n",
            "Epoch [5/5], Batch [700/938], Loss: 0.4217\n",
            "Epoch [5/5], Batch [800/938], Loss: 0.3092\n",
            "Epoch [5/5], Batch [900/938], Loss: 0.3613\n",
            "Epoch [5/5], Loss: 0.4845, Accuracy: 0.8342\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mô hình được train với CIFAR-10 cho accuracy cao nhất sau 5 epochs. Mô hình này có accuracy cao nhất là vì có thể dataset CIFAR có nhiều feature gần giống với dataset FashionMNIST so với dataset MNIST. Tuy nhiên nếu train thêm nhiều epochs nữa thì model MiniVGG train from scratch sẽ tốt hơn 2 model pretrain vì các layer sẽ fit được với FashionMNIST dataset tốt hơn 2 model pretrain kia. 2 model pretrain kia thì các layer đã bị freeze do vậy nếu train thêm nhiều epoch nữa thì layer của model cũng sẽ không học được điều gìtốt"
      ],
      "metadata": {
        "id": "ZxynRsVfNpZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models.feature_extraction import get_graph_node_names\n",
        "from torchvision.models.feature_extraction import create_feature_extractor\n",
        "\n",
        "train_nodes, eval_nodes = get_graph_node_names(model_HW3)"
      ],
      "metadata": {
        "id": "14KcL5hbOk5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_nodes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDNR8BjpP8Th",
        "outputId": "5876a66f-5f0c-4659-ca22-5970a6b1543b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['x',\n",
              " 'features.0',\n",
              " 'features.1',\n",
              " 'features.2',\n",
              " 'features.3',\n",
              " 'features.4',\n",
              " 'features.5',\n",
              " 'features.6',\n",
              " 'features.7',\n",
              " 'features.8',\n",
              " 'features.9',\n",
              " 'features.10',\n",
              " 'features.11',\n",
              " 'features.12',\n",
              " 'features.13',\n",
              " 'features.14',\n",
              " 'flatten',\n",
              " 'classifier']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "create_feature_extractor(model_HW3, train_return_nodes= train_nodes, eval_return_nodes= eval_nodes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJAiCDqvUipH",
        "outputId": "3e7ae8d9-5338-4401-f8b9-c8841f3d2415"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MiniVGG(\n",
              "  (features): Module(\n",
              "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU()\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU()\n",
              "    (9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU()\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU()\n",
              "    (14): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Linear(in_features=2304, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_HW3.features[0].weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjNYOkDTSmMv",
        "outputId": "9374163a-c879-43d6-bdcb-2b41a1bba6e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[[[-4.9261e-02, -3.3996e-02,  1.3932e-01],\n",
              "          [-2.9171e-01, -1.2294e-01, -2.0583e-01],\n",
              "          [-1.8300e-01, -1.1332e-01, -4.3617e-02]]],\n",
              "\n",
              "\n",
              "        [[[-2.8938e-01,  2.2051e-01, -6.5313e-02],\n",
              "          [ 2.4501e-01,  3.1906e-01,  1.0882e-01],\n",
              "          [-1.8060e-02, -2.8399e-01, -3.1272e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.2573e-02, -3.5681e-02, -2.2704e-02],\n",
              "          [ 1.9991e-01, -1.2565e-01,  2.1561e-01],\n",
              "          [ 1.6551e-01, -4.7146e-02, -2.1403e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.7682e-01,  2.4552e-01, -5.4870e-02],\n",
              "          [-1.1699e-01, -2.9124e-01, -2.7061e-01],\n",
              "          [ 2.8950e-01,  2.9127e-01,  1.0661e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.4823e-02, -1.4314e-01,  1.5886e-01],\n",
              "          [-1.0912e-01, -2.7046e-02, -1.2821e-01],\n",
              "          [ 1.1047e-01, -1.5646e-01,  2.6694e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 2.6849e-01,  3.1240e-01, -3.0154e-01],\n",
              "          [-2.0837e-01, -2.0277e-01, -1.7017e-01],\n",
              "          [-2.0373e-01,  1.4033e-01,  1.3967e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.1505e-01, -1.1403e-01, -6.0640e-02],\n",
              "          [ 5.8040e-02,  2.7372e-01, -3.1028e-01],\n",
              "          [ 1.2266e-01,  1.7674e-01,  3.0731e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 2.9363e-01,  2.3376e-01,  2.7647e-01],\n",
              "          [ 3.3175e-01,  1.1422e-01, -3.6343e-01],\n",
              "          [ 2.9833e-01,  1.7536e-01, -2.0797e-01]]],\n",
              "\n",
              "\n",
              "        [[[-6.7379e-02, -3.2985e-01, -1.7938e-01],\n",
              "          [ 2.6120e-01, -3.2442e-02,  2.0087e-01],\n",
              "          [-2.1021e-01, -8.1490e-03, -9.8325e-02]]],\n",
              "\n",
              "\n",
              "        [[[-3.1049e-01, -2.6813e-01, -1.8507e-01],\n",
              "          [-2.0829e-01, -1.3822e-01,  1.4401e-01],\n",
              "          [-1.7265e-01,  2.6060e-01,  2.5325e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 2.8828e-01,  3.1912e-01, -3.8321e-01],\n",
              "          [ 3.1599e-01, -8.9182e-02, -2.6194e-01],\n",
              "          [-6.2582e-02,  2.3203e-01, -1.3308e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.3608e-01,  3.1252e-03, -3.9012e-01],\n",
              "          [ 3.4285e-01,  1.8572e-01,  1.5690e-01],\n",
              "          [ 1.8348e-01, -2.2192e-01, -3.4997e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 9.8784e-02, -1.6291e-01, -1.4326e-01],\n",
              "          [ 2.4987e-02,  9.0734e-02,  3.0300e-01],\n",
              "          [ 1.0737e-01, -3.0383e-01,  2.5647e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 2.1679e-01, -7.1512e-02, -6.4873e-02],\n",
              "          [ 8.6272e-02,  2.9651e-01,  1.5908e-01],\n",
              "          [ 7.5529e-02,  1.3905e-01, -8.6889e-02]]],\n",
              "\n",
              "\n",
              "        [[[ 2.0044e-01,  1.1260e-01,  4.5804e-02],\n",
              "          [ 1.7180e-02, -2.3045e-01,  1.2618e-01],\n",
              "          [ 2.2945e-01, -1.1050e-01, -5.4378e-02]]],\n",
              "\n",
              "\n",
              "        [[[ 1.7839e-01, -2.1407e-01, -1.7263e-01],\n",
              "          [ 2.4790e-01,  2.3013e-01,  1.8193e-01],\n",
              "          [ 5.4775e-02, -3.7752e-02,  1.1687e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 2.6047e-01,  5.7416e-02,  3.3578e-01],\n",
              "          [-2.3404e-01,  3.4326e-02,  1.8352e-01],\n",
              "          [ 1.1144e-01, -1.5683e-01,  3.4744e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 3.0315e-01, -2.6687e-01,  1.3764e-01],\n",
              "          [-2.9856e-03, -2.4896e-02, -2.7601e-01],\n",
              "          [-3.1105e-01, -6.4837e-02, -1.2112e-01]]],\n",
              "\n",
              "\n",
              "        [[[-6.6181e-02, -1.1720e-01, -2.5674e-02],\n",
              "          [-1.9963e-01,  2.1368e-01,  2.8886e-01],\n",
              "          [ 3.0618e-01, -1.7909e-01,  3.4585e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.4332e-01,  2.2349e-01,  2.7409e-02],\n",
              "          [-3.1459e-01,  3.0616e-01, -3.2295e-01],\n",
              "          [-1.5603e-01,  1.1135e-02,  2.2750e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 3.0920e-01, -2.1653e-01, -3.7065e-01],\n",
              "          [ 1.2639e-02, -2.7480e-01, -3.2962e-01],\n",
              "          [ 2.2973e-03, -1.3316e-01, -9.2319e-02]]],\n",
              "\n",
              "\n",
              "        [[[-6.1919e-02, -3.0359e-01,  2.6252e-01],\n",
              "          [-3.1196e-01,  1.6213e-01,  1.8748e-01],\n",
              "          [ 3.0321e-01, -1.3055e-01,  2.2744e-01]]],\n",
              "\n",
              "\n",
              "        [[[-2.6353e-01,  1.2808e-01, -1.2384e-01],\n",
              "          [ 1.6260e-01,  3.2373e-01, -2.8873e-01],\n",
              "          [ 3.2618e-02,  1.5805e-01, -1.8342e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.5620e-01,  1.0903e-01,  1.4279e-01],\n",
              "          [ 6.4655e-02,  1.1561e-01,  2.0761e-01],\n",
              "          [ 2.2937e-01,  2.1102e-01,  1.3694e-02]]],\n",
              "\n",
              "\n",
              "        [[[ 2.7886e-01,  9.4262e-02, -4.1540e-02],\n",
              "          [ 2.4463e-01,  2.6604e-01, -6.3303e-03],\n",
              "          [-1.3153e-01, -2.1775e-02, -3.0196e-01]]],\n",
              "\n",
              "\n",
              "        [[[-2.0644e-01, -2.3724e-01, -5.3315e-02],\n",
              "          [-6.9563e-02,  1.9425e-01, -3.6143e-01],\n",
              "          [-3.0170e-01,  1.8185e-01, -2.5674e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 8.3622e-02,  2.0155e-01,  1.0744e-01],\n",
              "          [-2.1046e-01, -4.4544e-02, -1.4880e-01],\n",
              "          [-2.0517e-01,  1.4461e-01, -2.2625e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 8.5635e-02, -2.9798e-01,  1.0967e-01],\n",
              "          [-1.1694e-01,  3.2419e-01,  2.4103e-01],\n",
              "          [-2.2266e-01,  1.1831e-01, -3.0356e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.3423e-01,  2.9732e-01,  1.0431e-01],\n",
              "          [-2.0193e-01,  2.5312e-01,  1.4339e-01],\n",
              "          [ 3.2082e-01,  2.1096e-01,  1.5856e-01]]],\n",
              "\n",
              "\n",
              "        [[[-3.2929e-01, -2.3734e-01,  6.3375e-02],\n",
              "          [-2.1041e-01,  2.4020e-01,  2.0088e-01],\n",
              "          [-1.9342e-01, -2.0345e-01, -2.6585e-02]]],\n",
              "\n",
              "\n",
              "        [[[ 2.6923e-01,  2.1994e-01,  1.9488e-01],\n",
              "          [-2.7289e-01, -2.2340e-01,  2.7688e-01],\n",
              "          [-3.0200e-01, -1.9135e-01, -7.1864e-02]]],\n",
              "\n",
              "\n",
              "        [[[ 5.2076e-02,  2.8708e-01, -9.4484e-02],\n",
              "          [-4.0691e-02,  1.8551e-01, -3.5764e-01],\n",
              "          [ 1.1611e-01,  1.3771e-01, -1.4708e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 2.9626e-01, -8.8274e-03,  1.3704e-01],\n",
              "          [-6.5398e-02,  1.9142e-01, -2.8848e-01],\n",
              "          [-2.8215e-01, -9.1340e-02,  3.1694e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 3.2641e-01, -2.8775e-01,  1.4236e-01],\n",
              "          [ 3.2156e-01,  2.0141e-01, -2.0343e-01],\n",
              "          [ 3.3457e-02, -3.4905e-01, -2.8712e-03]]],\n",
              "\n",
              "\n",
              "        [[[ 1.0185e-01,  2.9895e-01, -9.5361e-02],\n",
              "          [-1.4407e-01, -1.0885e-02, -3.5134e-02],\n",
              "          [-1.1658e-01,  3.0460e-01,  1.2056e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 9.6260e-02, -2.4310e-01, -1.9241e-01],\n",
              "          [ 1.1139e-01, -1.9249e-02,  2.8296e-01],\n",
              "          [-2.5033e-01, -1.5327e-01,  3.0830e-02]]],\n",
              "\n",
              "\n",
              "        [[[ 1.1271e-01,  2.2066e-01,  2.9561e-01],\n",
              "          [-2.1781e-01,  3.7361e-02, -3.1897e-01],\n",
              "          [-9.2121e-02,  4.7506e-02,  1.5358e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.8539e-01, -2.9501e-01,  2.7919e-01],\n",
              "          [ 2.8719e-02,  1.9310e-01, -2.9849e-01],\n",
              "          [ 2.2219e-01, -2.1500e-01,  2.9511e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 5.6422e-02,  5.1951e-02,  5.6975e-02],\n",
              "          [-3.0582e-01, -1.8473e-01,  2.6163e-02],\n",
              "          [-1.9019e-01, -2.5114e-01, -1.1166e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.1887e-01,  1.4421e-01,  1.1828e-01],\n",
              "          [-3.3125e-01, -9.1261e-02,  3.0817e-01],\n",
              "          [-2.5596e-01, -2.1172e-01,  4.5241e-02]]],\n",
              "\n",
              "\n",
              "        [[[ 1.8235e-01, -4.2909e-02,  4.0998e-02],\n",
              "          [-3.4465e-01,  1.1675e-01,  1.0083e-01],\n",
              "          [-1.9939e-01, -2.4147e-01,  4.8498e-02]]],\n",
              "\n",
              "\n",
              "        [[[-2.1154e-01, -3.8327e-01, -2.3297e-01],\n",
              "          [-2.1718e-01, -3.3732e-01,  7.4560e-02],\n",
              "          [ 3.6462e-01, -1.3913e-01,  2.3680e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.9684e-02, -1.7100e-02, -2.5513e-01],\n",
              "          [ 1.6447e-02,  3.5180e-02,  2.8912e-01],\n",
              "          [-2.3084e-01, -1.5675e-01, -1.6316e-01]]],\n",
              "\n",
              "\n",
              "        [[[-8.8636e-02,  1.7231e-01,  5.9320e-02],\n",
              "          [ 1.7487e-01, -3.3465e-01,  6.0206e-02],\n",
              "          [-2.8543e-01,  1.2375e-01, -2.8147e-01]]],\n",
              "\n",
              "\n",
              "        [[[-2.7298e-01,  2.7484e-01,  1.1648e-01],\n",
              "          [-2.7960e-02, -2.8083e-01,  3.5272e-01],\n",
              "          [-2.9511e-01,  2.5692e-01, -1.8954e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 3.1704e-01,  7.6133e-02, -1.2044e-01],\n",
              "          [-1.4935e-01, -3.1478e-01,  2.6891e-01],\n",
              "          [-6.1543e-02,  2.7334e-01,  1.0647e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 4.6320e-02,  1.3541e-01, -3.4348e-01],\n",
              "          [-1.5800e-01,  1.0265e-01, -1.6812e-01],\n",
              "          [ 1.7330e-01,  2.8253e-01,  2.6270e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 2.6975e-01,  7.2046e-02,  2.6450e-02],\n",
              "          [-4.4848e-02, -2.2316e-01, -1.4085e-01],\n",
              "          [-2.5465e-01,  1.2868e-01, -2.7812e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 3.1258e-01, -3.4400e-01, -8.6535e-02],\n",
              "          [ 8.2607e-03, -2.1752e-01,  2.4803e-04],\n",
              "          [-9.9019e-02,  2.0909e-01, -2.6525e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 7.8849e-02, -2.7788e-01,  1.8374e-01],\n",
              "          [ 1.1411e-01, -1.0358e-01, -2.3956e-01],\n",
              "          [ 7.9927e-02, -3.3884e-01,  2.1728e-01]]],\n",
              "\n",
              "\n",
              "        [[[-2.3659e-01, -3.2432e-02, -1.7015e-01],\n",
              "          [ 2.9114e-01, -1.3689e-01, -2.3762e-01],\n",
              "          [ 2.9729e-01,  2.2662e-01, -1.4772e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 2.7440e-01,  1.3173e-01,  3.1989e-01],\n",
              "          [-6.3300e-03,  2.7482e-01,  1.7050e-01],\n",
              "          [ 2.8859e-01, -2.9199e-01,  2.2071e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.6253e-01, -1.0694e-01,  1.1134e-02],\n",
              "          [ 1.9484e-01, -2.6828e-01,  2.7697e-02],\n",
              "          [ 9.8204e-02,  1.2584e-01,  2.5863e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.8077e-01, -5.1324e-02, -1.4136e-01],\n",
              "          [ 3.0596e-01,  2.8872e-01,  5.8279e-02],\n",
              "          [ 6.1695e-02,  9.1034e-02,  1.5248e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.8933e-01,  1.1266e-01, -2.1220e-01],\n",
              "          [-3.0896e-01,  1.3752e-01,  6.3390e-02],\n",
              "          [-1.2034e-01,  2.4225e-01,  1.4876e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.3016e-01,  1.5573e-01, -7.0742e-02],\n",
              "          [-2.4117e-01, -4.5336e-02,  2.0100e-01],\n",
              "          [-3.5125e-01,  3.1709e-01, -2.5118e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.6661e-01,  3.3060e-01, -4.4416e-02],\n",
              "          [ 2.0293e-01, -1.5992e-01,  2.2213e-01],\n",
              "          [ 1.8226e-01,  2.7615e-02, -1.9287e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 2.9453e-02, -2.0459e-01, -2.1189e-01],\n",
              "          [-2.5175e-01, -3.9422e-01, -2.9871e-01],\n",
              "          [ 3.3966e-01, -1.8213e-01, -1.6300e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.9692e-01,  1.4662e-01, -8.8849e-03],\n",
              "          [ 1.4701e-01, -1.5952e-01,  3.9177e-02],\n",
              "          [-1.7508e-01,  2.4622e-01,  2.4044e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.3010e-01,  3.8246e-02,  2.5316e-01],\n",
              "          [ 3.1304e-01,  2.9910e-01,  3.0032e-01],\n",
              "          [ 1.5817e-01,  1.4629e-02,  2.5763e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.1446e-01,  1.6105e-01,  4.3152e-02],\n",
              "          [-2.5301e-01, -8.2938e-02, -8.1119e-02],\n",
              "          [ 2.2681e-01,  1.1563e-01,  2.2785e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 2.4423e-01, -2.9612e-01,  2.9856e-01],\n",
              "          [ 1.9251e-01,  2.8308e-01, -2.2131e-01],\n",
              "          [ 7.6050e-02,  4.4868e-02, -5.6002e-02]]],\n",
              "\n",
              "\n",
              "        [[[ 1.9722e-01, -1.9812e-01,  2.8438e-01],\n",
              "          [-3.2046e-01,  1.6690e-01, -8.1637e-02],\n",
              "          [ 2.7227e-01,  2.4855e-01, -1.2608e-01]]],\n",
              "\n",
              "\n",
              "        [[[-2.3002e-02, -1.2861e-01,  1.3304e-02],\n",
              "          [-3.0119e-02, -3.3029e-01,  1.0772e-01],\n",
              "          [-1.0736e-01,  7.7230e-02,  1.2968e-01]]]], device='cuda:0',\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}