{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgqonaGvYwzx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIBhyaXbY0tK",
        "outputId": "036ac03d-199c-4bc2-8d0a-636e13d13752"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import collections\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "XlF5xecFY1Pq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BOX_PATH = \"/content/drive/MyDrive/data/train_bboxes.npy\"\n",
        "IMAGE_PATH = \"/content/drive/MyDrive/data/train_X.npy\"\n",
        "LABEL_PATH = \"/content/drive/MyDrive/data/train_Y.npy\"\n",
        "SEGMENT_PATH = \"/content/drive/MyDrive/data/train_seg.npy\"\n",
        "\n",
        "train_boxes = np.load(BOX_PATH)\n",
        "train_segments = np.load(SEGMENT_PATH).reshape(55000, 64, 64)\n",
        "train_images = np.load(IMAGE_PATH)\n",
        "train_labels = np.load(LABEL_PATH)"
      ],
      "metadata": {
        "id": "JFisxhEsY_LM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5000):\n",
        "  mask_file = str(i) + \"_mask.png\"\n",
        "  image_file = str(i) + \".png\"\n",
        "  img = Image.fromarray(train_images[i].reshape((64,64,3)), 'RGB')\n",
        "  img.save(os.path.join(\"/content/drive/MyDrive/mnist segment/image/\", image_file))\n",
        "  img = Image.fromarray(train_segments[i].reshape((64,64)))\n",
        "  img.save(os.path.join(\"/content/drive/MyDrive/mnist segment/mask/\", mask_file))"
      ],
      "metadata": {
        "id": "vdTpvlQUY_9E"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BOX_PATH = \"/content/drive/MyDrive/data/valid_bboxes.npy\"\n",
        "IMAGE_PATH = \"/content/drive/MyDrive/data/valid_X.npy\"\n",
        "LABEL_PATH = \"/content/drive/MyDrive/data/valid_Y.npy\"\n",
        "SEGMENT_PATH = \"/content/drive/MyDrive/data/valid_seg.npy\"\n",
        "\n",
        "val_boxes = np.load(BOX_PATH)\n",
        "val_segments = np.load(SEGMENT_PATH).reshape(5000, 64, 64)\n",
        "val_images = np.load(IMAGE_PATH)\n",
        "val_labels = np.load(LABEL_PATH)"
      ],
      "metadata": {
        "id": "OShBLpH_cRZV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5000):\n",
        "  mask_file = str(i) + \"_mask.png\"\n",
        "  image_file = str(i) + \".png\"\n",
        "  img = Image.fromarray(val_images[i].reshape((64,64,3)), 'RGB')\n",
        "  img.save(os.path.join(\"/content/drive/MyDrive/mnist segment valid/image/\", image_file))\n",
        "  img = Image.fromarray(val_segments[i].reshape((64,64)))\n",
        "  img.save(os.path.join(\"/content/drive/MyDrive/mnist segment valid/mask/\", mask_file))"
      ],
      "metadata": {
        "id": "fuMaMqbjcIqI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "from torchvision.io import read_image\n",
        "from torchvision.ops.boxes import masks_to_boxes\n",
        "from torchvision import tv_tensors\n",
        "from torchvision.transforms.v2 import functional as F\n",
        "\n",
        "\n",
        "class MNISTDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, transforms):\n",
        "        self.root = root\n",
        "        self.transforms = transforms\n",
        "\n",
        "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"image\"))))\n",
        "        self.masks = list(sorted(os.listdir(os.path.join(root, \"mask\"))))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        img_path = os.path.join(self.root, \"image\", self.imgs[idx])\n",
        "        mask_path = os.path.join(self.root, \"mask\", self.masks[idx])\n",
        "        img = read_image(img_path)\n",
        "        mask = read_image(mask_path)\n",
        "        obj_ids = torch.unique(mask)\n",
        "        obj_ids = obj_ids[:-1]\n",
        "        num_objs = len(obj_ids)\n",
        "        masks = (mask == obj_ids[:, None, None]).to(dtype=torch.uint8)\n",
        "\n",
        "        boxes = masks_to_boxes(masks)\n",
        "\n",
        "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
        "\n",
        "        image_id = idx\n",
        "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "        # suppose all instances are not crowd\n",
        "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
        "\n",
        "        # Wrap sample and targets into torchvision tv_tensors:\n",
        "        img = tv_tensors.Image(img)\n",
        "\n",
        "        target = {}\n",
        "        target[\"boxes\"] = tv_tensors.BoundingBoxes(boxes, format=\"XYXY\", canvas_size=F.get_size(img))\n",
        "        target[\"masks\"] = tv_tensors.Mask(masks)\n",
        "        target[\"labels\"] = labels\n",
        "        target[\"image_id\"] = image_id\n",
        "        target[\"area\"] = area\n",
        "        target[\"iscrowd\"] = iscrowd\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            img, target = self.transforms(img, target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)"
      ],
      "metadata": {
        "id": "0lxrHfycai2l"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
      ],
      "metadata": {
        "id": "X0GWnedMZ2zb"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "\n",
        "\n",
        "backbone.out_channels = 1280\n",
        "\n",
        "\n",
        "anchor_generator = AnchorGenerator(\n",
        "    sizes=((32, 64, 128, 256, 512),),\n",
        "    aspect_ratios=((0.5, 1.0, 2.0),)\n",
        ")\n",
        "\n",
        "roi_pooler = torchvision.ops.MultiScaleRoIAlign(\n",
        "    featmap_names=['0'],\n",
        "    output_size=7,\n",
        "    sampling_ratio=2,\n",
        ")\n",
        "\n",
        "model = FasterRCNN(\n",
        "    backbone,\n",
        "    num_classes=10,\n",
        "    rpn_anchor_generator=anchor_generator,\n",
        "    box_roi_pool=roi_pooler,\n",
        ")"
      ],
      "metadata": {
        "id": "0zPxYL_jbHzJ"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "\n",
        "\n",
        "def get_model_instance_segmentation(num_classes):\n",
        "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
        "\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    # replace the pre-trained head with a new one\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "    hidden_layer = 256\n",
        "    model.roi_heads.mask_predictor = MaskRCNNPredictor(\n",
        "        in_features_mask,\n",
        "        hidden_layer,\n",
        "        num_classes,\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "sLi08fRybMJz"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/engine.py\")\n",
        "os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/utils.py\")\n",
        "os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_utils.py\")\n",
        "os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_eval.py\")\n",
        "os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/transforms.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vk0TTLQbRM-",
        "outputId": "28421a0c-42c1-4346-91e9-0a0c3e553754"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import v2 as T\n",
        "\n",
        "\n",
        "def get_transform(train):\n",
        "    transforms = []\n",
        "    if train:\n",
        "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
        "    transforms.append(T.ToDtype(torch.float, scale=True))\n",
        "    transforms.append(T.ToPureTensor())\n",
        "    return T.Compose(transforms)"
      ],
      "metadata": {
        "id": "4IR1-27wbWqX"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from engine import train_one_epoch, evaluate\n",
        "import utils\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "num_classes = 10\n",
        "dataset = MNISTDataset('/content/drive/MyDrive/mnist segment', get_transform(train=True))\n",
        "dataset_test = MNISTDataset('/content/drive/MyDrive/mnist segment valid', get_transform(train=False))\n",
        "\n",
        "indices = torch.randperm(len(dataset)).tolist()\n",
        "dataset = torch.utils.data.Subset(dataset, indices[:-50])\n",
        "dataset_test = torch.utils.data.Subset(dataset_test, indices[-50:])\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    collate_fn=utils.collate_fn\n",
        ")\n",
        "\n",
        "data_loader_test = torch.utils.data.DataLoader(\n",
        "    dataset_test,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        "    collate_fn=utils.collate_fn\n",
        ")\n",
        "\n",
        "model = get_model_instance_segmentation(num_classes)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(\n",
        "    params,\n",
        "    lr=0.005,\n",
        "    momentum=0.9,\n",
        "    weight_decay=0.0005\n",
        ")\n",
        "\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
        "    optimizer,\n",
        "    step_size=3,\n",
        "    gamma=0.1\n",
        ")\n",
        "\n",
        "# let's train it for 5 epochs\n",
        "num_epochs = 2\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=100)\n",
        "    lr_scheduler.step()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KxnILIobl02",
        "outputId": "e84ddb7d-1d69-4283-8924-d404086dc70f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0]  [   0/1119]  eta: 0:12:03  lr: 0.000010  loss: 3.5410 (3.5410)  loss_classifier: 2.2861 (2.2861)  loss_box_reg: 0.0276 (0.0276)  loss_mask: 0.8891 (0.8891)  loss_objectness: 0.3016 (0.3016)  loss_rpn_box_reg: 0.0367 (0.0367)  time: 0.6466  data: 0.2012  max mem: 2166\n",
            "Epoch: [0]  [ 100/1119]  eta: 0:07:08  lr: 0.000509  loss: 0.8835 (1.2667)  loss_classifier: 0.1529 (0.4254)  loss_box_reg: 0.1229 (0.0873)  loss_mask: 0.5782 (0.6589)  loss_objectness: 0.0222 (0.0761)  loss_rpn_box_reg: 0.0104 (0.0190)  time: 0.4188  data: 0.0096  max mem: 2335\n",
            "Epoch: [0]  [ 200/1119]  eta: 0:06:24  lr: 0.001009  loss: 0.9045 (1.1224)  loss_classifier: 0.1476 (0.2936)  loss_box_reg: 0.1479 (0.1260)  loss_mask: 0.5784 (0.6334)  loss_objectness: 0.0191 (0.0548)  loss_rpn_box_reg: 0.0054 (0.0147)  time: 0.4105  data: 0.0064  max mem: 2335\n",
            "Epoch: [0]  [ 300/1119]  eta: 0:05:45  lr: 0.001508  loss: 1.0756 (1.0898)  loss_classifier: 0.2052 (0.2579)  loss_box_reg: 0.2205 (0.1507)  loss_mask: 0.6291 (0.6239)  loss_objectness: 0.0315 (0.0448)  loss_rpn_box_reg: 0.0050 (0.0124)  time: 0.4310  data: 0.0094  max mem: 2336\n",
            "Epoch: [0]  [ 400/1119]  eta: 0:05:03  lr: 0.002008  loss: 1.0027 (1.0852)  loss_classifier: 0.1696 (0.2417)  loss_box_reg: 0.1833 (0.1656)  loss_mask: 0.5990 (0.6215)  loss_objectness: 0.0344 (0.0443)  loss_rpn_box_reg: 0.0068 (0.0121)  time: 0.4170  data: 0.0070  max mem: 2336\n",
            "Epoch: [0]  [ 500/1119]  eta: 0:04:21  lr: 0.002507  loss: 1.1164 (1.0822)  loss_classifier: 0.2208 (0.2333)  loss_box_reg: 0.2437 (0.1762)  loss_mask: 0.6271 (0.6214)  loss_objectness: 0.0209 (0.0400)  loss_rpn_box_reg: 0.0078 (0.0113)  time: 0.4289  data: 0.0081  max mem: 2336\n",
            "Epoch: [0]  [ 600/1119]  eta: 0:03:40  lr: 0.003007  loss: 1.1783 (1.0869)  loss_classifier: 0.2196 (0.2303)  loss_box_reg: 0.2771 (0.1877)  loss_mask: 0.6351 (0.6213)  loss_objectness: 0.0227 (0.0370)  loss_rpn_box_reg: 0.0043 (0.0106)  time: 0.4364  data: 0.0101  max mem: 2336\n",
            "Epoch: [0]  [ 700/1119]  eta: 0:02:58  lr: 0.003506  loss: 1.0307 (1.0874)  loss_classifier: 0.1824 (0.2269)  loss_box_reg: 0.2020 (0.1941)  loss_mask: 0.6030 (0.6205)  loss_objectness: 0.0194 (0.0357)  loss_rpn_box_reg: 0.0043 (0.0102)  time: 0.4223  data: 0.0068  max mem: 2336\n",
            "Epoch: [0]  [ 800/1119]  eta: 0:02:15  lr: 0.004006  loss: 1.0725 (1.0898)  loss_classifier: 0.1988 (0.2254)  loss_box_reg: 0.2169 (0.2002)  loss_mask: 0.6227 (0.6205)  loss_objectness: 0.0224 (0.0340)  loss_rpn_box_reg: 0.0042 (0.0098)  time: 0.4357  data: 0.0082  max mem: 2336\n",
            "Epoch: [0]  [ 900/1119]  eta: 0:01:33  lr: 0.004505  loss: 1.1302 (1.0891)  loss_classifier: 0.2263 (0.2234)  loss_box_reg: 0.2510 (0.2037)  loss_mask: 0.6317 (0.6199)  loss_objectness: 0.0164 (0.0326)  loss_rpn_box_reg: 0.0038 (0.0094)  time: 0.4326  data: 0.0068  max mem: 2336\n",
            "Epoch: [0]  [1000/1119]  eta: 0:00:50  lr: 0.005000  loss: 1.0717 (1.0883)  loss_classifier: 0.1869 (0.2211)  loss_box_reg: 0.2352 (0.2062)  loss_mask: 0.6218 (0.6201)  loss_objectness: 0.0269 (0.0317)  loss_rpn_box_reg: 0.0047 (0.0091)  time: 0.4298  data: 0.0075  max mem: 2336\n",
            "Epoch: [0]  [1100/1119]  eta: 0:00:08  lr: 0.005000  loss: 1.0826 (1.0859)  loss_classifier: 0.1956 (0.2187)  loss_box_reg: 0.2325 (0.2079)  loss_mask: 0.6283 (0.6197)  loss_objectness: 0.0138 (0.0308)  loss_rpn_box_reg: 0.0033 (0.0088)  time: 0.4304  data: 0.0074  max mem: 2336\n",
            "Epoch: [0]  [1118/1119]  eta: 0:00:00  lr: 0.005000  loss: 1.0448 (1.0852)  loss_classifier: 0.1804 (0.2181)  loss_box_reg: 0.2111 (0.2080)  loss_mask: 0.6214 (0.6197)  loss_objectness: 0.0204 (0.0306)  loss_rpn_box_reg: 0.0041 (0.0087)  time: 0.4262  data: 0.0074  max mem: 2336\n",
            "Epoch: [0] Total time: 0:07:58 (0.4274 s / it)\n",
            "Epoch: [1]  [   0/1119]  eta: 0:11:50  lr: 0.005000  loss: 1.0843 (1.0843)  loss_classifier: 0.1929 (0.1929)  loss_box_reg: 0.1834 (0.1834)  loss_mask: 0.6551 (0.6551)  loss_objectness: 0.0300 (0.0300)  loss_rpn_box_reg: 0.0229 (0.0229)  time: 0.6348  data: 0.2124  max mem: 2336\n",
            "Epoch: [1]  [ 100/1119]  eta: 0:07:23  lr: 0.005000  loss: 1.0519 (1.0914)  loss_classifier: 0.1967 (0.2099)  loss_box_reg: 0.2317 (0.2312)  loss_mask: 0.6171 (0.6157)  loss_objectness: 0.0157 (0.0274)  loss_rpn_box_reg: 0.0041 (0.0072)  time: 0.4356  data: 0.0105  max mem: 2336\n",
            "Epoch: [1]  [ 200/1119]  eta: 0:06:38  lr: 0.005000  loss: 1.1423 (1.0910)  loss_classifier: 0.2296 (0.2093)  loss_box_reg: 0.2575 (0.2321)  loss_mask: 0.6236 (0.6186)  loss_objectness: 0.0189 (0.0241)  loss_rpn_box_reg: 0.0046 (0.0069)  time: 0.4331  data: 0.0076  max mem: 2336\n",
            "Epoch: [1]  [ 300/1119]  eta: 0:05:54  lr: 0.005000  loss: 0.9877 (1.0810)  loss_classifier: 0.1600 (0.2047)  loss_box_reg: 0.1713 (0.2270)  loss_mask: 0.6060 (0.6181)  loss_objectness: 0.0168 (0.0239)  loss_rpn_box_reg: 0.0038 (0.0072)  time: 0.4248  data: 0.0082  max mem: 2336\n",
            "Epoch: [1]  [ 400/1119]  eta: 0:05:11  lr: 0.005000  loss: 1.0962 (1.0843)  loss_classifier: 0.2104 (0.2046)  loss_box_reg: 0.2437 (0.2279)  loss_mask: 0.6347 (0.6194)  loss_objectness: 0.0142 (0.0254)  loss_rpn_box_reg: 0.0033 (0.0069)  time: 0.4380  data: 0.0087  max mem: 2336\n",
            "Epoch: [1]  [ 500/1119]  eta: 0:04:28  lr: 0.005000  loss: 1.0399 (1.0754)  loss_classifier: 0.1820 (0.2008)  loss_box_reg: 0.1914 (0.2231)  loss_mask: 0.6103 (0.6190)  loss_objectness: 0.0247 (0.0257)  loss_rpn_box_reg: 0.0050 (0.0068)  time: 0.4239  data: 0.0063  max mem: 2337\n",
            "Epoch: [1]  [ 600/1119]  eta: 0:03:45  lr: 0.005000  loss: 1.0274 (1.0679)  loss_classifier: 0.1916 (0.1980)  loss_box_reg: 0.2104 (0.2195)  loss_mask: 0.6100 (0.6183)  loss_objectness: 0.0192 (0.0251)  loss_rpn_box_reg: 0.0040 (0.0070)  time: 0.4343  data: 0.0098  max mem: 2337\n",
            "Epoch: [1]  [ 700/1119]  eta: 0:03:01  lr: 0.005000  loss: 1.1158 (1.0701)  loss_classifier: 0.2263 (0.1991)  loss_box_reg: 0.2421 (0.2203)  loss_mask: 0.6215 (0.6187)  loss_objectness: 0.0184 (0.0251)  loss_rpn_box_reg: 0.0044 (0.0068)  time: 0.4335  data: 0.0081  max mem: 2337\n",
            "Epoch: [1]  [ 800/1119]  eta: 0:02:18  lr: 0.005000  loss: 1.0186 (1.0672)  loss_classifier: 0.1817 (0.1984)  loss_box_reg: 0.2013 (0.2188)  loss_mask: 0.6148 (0.6184)  loss_objectness: 0.0191 (0.0248)  loss_rpn_box_reg: 0.0044 (0.0068)  time: 0.4289  data: 0.0075  max mem: 2337\n",
            "Epoch: [1]  [ 900/1119]  eta: 0:01:34  lr: 0.005000  loss: 1.0446 (1.0667)  loss_classifier: 0.1937 (0.1982)  loss_box_reg: 0.2028 (0.2188)  loss_mask: 0.6128 (0.6180)  loss_objectness: 0.0213 (0.0248)  loss_rpn_box_reg: 0.0057 (0.0068)  time: 0.4343  data: 0.0107  max mem: 2337\n",
            "Epoch: [1]  [1000/1119]  eta: 0:00:51  lr: 0.005000  loss: 1.0387 (1.0641)  loss_classifier: 0.1675 (0.1974)  loss_box_reg: 0.1826 (0.2178)  loss_mask: 0.6141 (0.6174)  loss_objectness: 0.0235 (0.0245)  loss_rpn_box_reg: 0.0064 (0.0069)  time: 0.4257  data: 0.0066  max mem: 2337\n",
            "Epoch: [1]  [1100/1119]  eta: 0:00:08  lr: 0.005000  loss: 1.0744 (1.0628)  loss_classifier: 0.1966 (0.1970)  loss_box_reg: 0.2311 (0.2173)  loss_mask: 0.6286 (0.6174)  loss_objectness: 0.0179 (0.0242)  loss_rpn_box_reg: 0.0040 (0.0069)  time: 0.4343  data: 0.0089  max mem: 2337\n",
            "Epoch: [1]  [1118/1119]  eta: 0:00:00  lr: 0.005000  loss: 1.0336 (1.0621)  loss_classifier: 0.1822 (0.1968)  loss_box_reg: 0.2059 (0.2170)  loss_mask: 0.6197 (0.6174)  loss_objectness: 0.0162 (0.0241)  loss_rpn_box_reg: 0.0042 (0.0069)  time: 0.4270  data: 0.0062  max mem: 2337\n",
            "Epoch: [1] Total time: 0:08:04 (0.4328 s / it)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import draw_bounding_boxes, draw_segmentation_masks\n",
        "\n",
        "image = read_image(\"/content/drive/MyDrive/mnist segment valid/image/1.png\")\n",
        "eval_transform = get_transform(train=False)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    x = eval_transform(image)\n",
        "    x = x.to(device)\n",
        "    predictions = model([x, ])\n",
        "    pred = predictions[0]\n",
        "\n",
        "image = (255.0 * (image - image.min()) / (image.max() - image.min())).to(torch.uint8)\n",
        "image = image[:3, ...]\n",
        "pred_labels = [f\"{score:.3f}\" for label, score in zip(pred[\"labels\"], pred[\"scores\"])]\n",
        "\n",
        "\n",
        "masks = (pred[\"masks\"] > 0.9).squeeze(1)\n",
        "output_image = draw_segmentation_masks(image, masks, alpha=0.0, colors=\"blue\")\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.imshow(output_image.permute(1, 2, 0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "id": "DUpevI8Vd6xy",
        "outputId": "b0c586aa-fe17-427e-d8fc-bf497e797ad5"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7d0a557b1300>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ohQ_nQMNuxlv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}